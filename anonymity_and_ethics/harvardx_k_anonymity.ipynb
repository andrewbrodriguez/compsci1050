{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "761d2176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "DATA_PATH = \"/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/reduced_qi_filled.csv\"\n",
    "OUT_RECORD_SUPP = \"/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/record_suppression.csv\"\n",
    "OUT_COLUMN_SUPP = \"/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/column_suppression.csv\"\n",
    "OUT_GEN_STAGE1 = \"/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/generalized_stage1.csv\"\n",
    "OUT_GEN_STAGE2 = \"/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/generalized_stage2.csv\"\n",
    "OUT_GEN_TOPSTAR = \"/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/generalized_stage3_topstar.csv\"\n",
    "OUT_COMBINATION = \"/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/combination.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feebaf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 199999\n",
      "Columns: ['course_id', 'user_id', 'cc_by_ip', 'city', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cc_by_ip</th>\n",
       "      <th>city</th>\n",
       "      <th>postalCode</th>\n",
       "      <th>LoE</th>\n",
       "      <th>YoB</th>\n",
       "      <th>gender</th>\n",
       "      <th>nforum_posts</th>\n",
       "      <th>nforum_votes</th>\n",
       "      <th>nforum_endorsed</th>\n",
       "      <th>nforum_threads</th>\n",
       "      <th>nforum_comments</th>\n",
       "      <th>nforum_pinned</th>\n",
       "      <th>nforum_events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>29940</td>\n",
       "      <td>US</td>\n",
       "      <td>Austin</td>\n",
       "      <td>78713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>37095</td>\n",
       "      <td>BD</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HarvardX/PH525.1x/1T2018</td>\n",
       "      <td>45634</td>\n",
       "      <td>CO</td>\n",
       "      <td>Medellín</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>m</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  course_id  user_id cc_by_ip      city postalCode  LoE  \\\n",
       "0  HarvardX/PH525.1x/1T2018    29940       US    Austin      78713  NaN   \n",
       "1  HarvardX/PH525.1x/1T2018    37095       BD     Dhaka        NaN    b   \n",
       "2  HarvardX/PH525.1x/1T2018    45634       CO  Medellín        NaN    m   \n",
       "\n",
       "      YoB gender  nforum_posts  nforum_votes  nforum_endorsed  nforum_threads  \\\n",
       "0     NaN    NaN             0             0                0               0   \n",
       "1  1991.0      m             0             0                0               0   \n",
       "2  1982.0      m             0             0                0               0   \n",
       "\n",
       "   nforum_comments  nforum_pinned  nforum_events  \n",
       "0                0              0              0  \n",
       "1                0              0              0  \n",
       "2                0              0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f58deeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifiers: ['user_id', 'course_id']\n",
      "QI columns (13): ['cc_by_ip', 'city', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', 'nforum_events']\n"
     ]
    }
   ],
   "source": [
    "# so user_id and course_id are idenitifiers here\n",
    "identifiers = [\"user_id\", \"course_id\"]\n",
    "qi_cols = [c for c in df.columns if c not in identifiers]\n",
    "\n",
    "print(\"Identifiers:\", identifiers)\n",
    "print(\"QI columns ({}):\".format(len(qi_cols)), qi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01fdb79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline k-anonymity: 1\n"
     ]
    }
   ],
   "source": [
    "# Okay lets check our baseline k anon\n",
    "# to do so im gonna make a helper\n",
    "from typing import List, Tuple\n",
    "\n",
    "def k_anonymity_level(data: pd.DataFrame, qis: List[str]) -> int:\n",
    "    # So the level of k anonmyity is data grouped by quasi ids\n",
    "    return int(data.groupby(qis, dropna=False).size().min())\n",
    "\n",
    "k0 = k_anonymity_level(df, qi_cols)\n",
    "print(\"Baseline k-anonymity:\", k0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2adb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_suppression_k(data: pd.DataFrame, qis: List[str], k: int = 5) -> Tuple[pd.DataFrame, int]:\n",
    "    # Okay so for record supression we only keep rows of size k\n",
    "    # where k is 5\n",
    "    sizes = data.groupby(qis, dropna=False).size().rename(\"size\")\n",
    "    tmp = data.join(sizes, on=qis)\n",
    "    kept = tmp[tmp[\"size\"] >= k].drop(columns=[\"size\"])\n",
    "    deleted = len(tmp) - len(kept)\n",
    "    return kept, deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef071ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rows_source': 199999, 'deleted_rows': 150286, 'rows_kept': 49713, 'k_after': 5, 'file': '/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/record_suppression.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Now we want to record supress to k = 5\n",
    "rs_df, rs_deleted = record_suppression_k(df, qi_cols, k=5)\n",
    "rs_k = k_anonymity_level(rs_df, qi_cols)\n",
    "rs_df.to_csv(OUT_RECORD_SUPP, index=False)\n",
    "\n",
    "print({\n",
    "    \"rows_source\": len(df),\n",
    "    \"deleted_rows\": rs_deleted,\n",
    "    \"rows_kept\": len(rs_df),\n",
    "    \"k_after\": rs_k,\n",
    "    \"file\": OUT_RECORD_SUPP\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274f4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_column_suppression_until_k(data, identifiers, target_k=5, count_na_as_value=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Greedy column suppression that drops the QI with the HIGHEST per-column cardinality\n",
    "    (most unique values) each step. Ties are broken by the k achieved after dropping\n",
    "    the column, then by resulting #groups (fewer is better), then by column name.\n",
    "    \"\"\"\n",
    "    # Start with all QIs\n",
    "    current_qis = [c for c in data.columns if c not in identifiers]\n",
    "    dropped = []\n",
    "\n",
    "    # Current k\n",
    "    current_k = k_anonymity_level(data, current_qis)\n",
    "    if verbose:\n",
    "        print(f\"Start: k={current_k}, QIs={len(current_qis)}\")\n",
    "\n",
    "    # How to count uniques (count NaN as its own value or not)\n",
    "    nunique_kwargs = {\"dropna\": not count_na_as_value}\n",
    "\n",
    "    # Precompute per-column cardinalities (they don’t change as we drop other columns)\n",
    "    cardinality = {c: data[c].nunique(**nunique_kwargs) for c in current_qis}\n",
    "\n",
    "    while current_k < target_k and current_qis:\n",
    "        # Find the maximum cardinality among remaining QIs\n",
    "        max_card = max(cardinality[c] for c in current_qis)\n",
    "        candidates = [c for c in current_qis if cardinality[c] == max_card]\n",
    "\n",
    "        # Tie-break among candidates: pick the one whose removal yields the highest k,\n",
    "        # then the fewest groups, then lexicographically.\n",
    "        best_col = None\n",
    "        best_k = -1\n",
    "        best_groups = None\n",
    "        best_name = None\n",
    "\n",
    "        for c in candidates:\n",
    "            trial_qis = [x for x in current_qis if x != c]\n",
    "            kval = k_anonymity_level(data, trial_qis)\n",
    "            ng = (data.groupby(trial_qis, dropna=False).ngroups if trial_qis else 1)\n",
    "\n",
    "            if (kval > best_k) or \\\n",
    "               (kval == best_k and (best_groups is None or ng < best_groups)) or \\\n",
    "               (kval == best_k and ng == best_groups and (best_name is None or c < best_name)):\n",
    "                best_k = kval\n",
    "                best_groups = ng\n",
    "                best_col = c\n",
    "                best_name = c\n",
    "\n",
    "        # Drop the chosen column\n",
    "        current_qis.remove(best_col)\n",
    "        dropped.append(best_col)\n",
    "        current_k = best_k\n",
    "        cardinality.pop(best_col, None)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Dropped '{best_col}' (card={max_card}) -> k={current_k}, QIs left={len(current_qis)}\")\n",
    "\n",
    "    return dropped, current_k, current_qis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ea94c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: k=1, QIs=13\n",
      "Dropped 'postalCode' (card=18489) -> k=1, QIs left=12\n",
      "Dropped 'city' (card=13276) -> k=1, QIs left=11\n",
      "Dropped 'nforum_events' (card=645) -> k=1, QIs left=10\n",
      "Dropped 'cc_by_ip' (card=218) -> k=1, QIs left=9\n",
      "Dropped 'YoB' (card=124) -> k=1, QIs left=8\n",
      "Dropped 'nforum_posts' (card=110) -> k=1, QIs left=7\n",
      "Dropped 'nforum_comments' (card=104) -> k=1, QIs left=6\n",
      "Dropped 'nforum_votes' (card=91) -> k=1, QIs left=5\n",
      "Dropped 'nforum_threads' (card=55) -> k=1, QIs left=4\n",
      "Dropped 'LoE' (card=12) -> k=1, QIs left=3\n",
      "Dropped 'nforum_endorsed' (card=11) -> k=1, QIs left=2\n",
      "Dropped 'nforum_pinned' (card=9) -> k=978, QIs left=1\n"
     ]
    }
   ],
   "source": [
    "dropped_cols, final_k, remaining_qis = greedy_column_suppression_until_k(\n",
    "    df, identifiers, target_k=5, count_na_as_value=True, verbose=True\n",
    ")\n",
    "\n",
    "# Save if you hit k >= 5\n",
    "if final_k >= 5:\n",
    "    keep_cols = identifiers + remaining_qis\n",
    "    cs_df = df[keep_cols].copy()\n",
    "    cs_df.to_csv(OUT_COLUMN_SUPP, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "336b710f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalization utilities\n",
    "def bin_counts(x):\n",
    "    xi = pd.to_numeric(x, errors=\"coerce\")\n",
    "    bins = [-np.inf, 0, 2, 5, 10, 20, np.inf]\n",
    "    labels = [\"0\", \"1-2\", \"3-5\", \"6-10\", \"11-20\", \"21+\"]\n",
    "    return pd.cut(xi.fillna(-np.inf), bins=bins, labels=labels, include_lowest=True).astype(str)\n",
    "\n",
    "def coarser_bin_counts(x):\n",
    "    xi = pd.to_numeric(x, errors=\"coerce\")\n",
    "    bins = [-np.inf, 0, 5, 20, np.inf]\n",
    "    labels = [\"0\", \"1-5\", \"6-20\", \"21+\"]\n",
    "    return pd.cut(xi.fillna(-np.inf), bins=bins, labels=labels, include_lowest=True).astype(str)\n",
    "\n",
    "def yob_to_decade(x):\n",
    "    xi = pd.to_numeric(x, errors=\"coerce\")\n",
    "    decade = (xi // 10) * 10\n",
    "    return decade.fillna(-1).astype(int).astype(str).replace({\"-1\": \"Unknown\"})\n",
    "\n",
    "def yob_to_20yr(x):\n",
    "    xi = pd.to_numeric(x, errors=\"coerce\")\n",
    "    band = (xi // 20) * 20\n",
    "    return band.fillna(-1).astype(int).astype(str).replace({\"-1\": \"Unknown\"})\n",
    "\n",
    "def postal3(x):\n",
    "    return x.astype(str).str[:3].replace({\"nan\": \"Unknown\", \"\": \"Unknown\"})\n",
    "\n",
    "def postal2(x):\n",
    "    return x.astype(str).str[:2].replace({\"nan\": \"Unknown\", \"\": \"Unknown\"})\n",
    "\n",
    "def generalize_stage1(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = data.copy()\n",
    "    lower = {c.lower(): c for c in g.columns}\n",
    "    # YoB -> decade\n",
    "    for key in [\"year of birth\", \"ear of birth\", \"yob\"]:\n",
    "        if key in lower:\n",
    "            g[lower[key]] = yob_to_decade(g[lower[key]])\n",
    "            break\n",
    "    # postal -> first 3\n",
    "    if \"postalcode\" in lower:\n",
    "        g[lower[\"postalcode\"]] = postal3(g[lower[\"postalcode\"]])\n",
    "    # Level of education -> buckets\n",
    "    if \"level of education\" in lower or \"loe\" in lower:\n",
    "        loe_col = lower.get(\"level of education\", lower.get(\"loe\"))\n",
    "        loe = g[loe_col].astype(str).str.lower()\n",
    "        def map_loe(s):\n",
    "            if any(k in s for k in [\"less than\", \"primary\", \"elementary\", \"secondary or less\", \"middle\", \"high school\", \"secondary\"]):\n",
    "                return \"≤Secondary\"\n",
    "            if \"associate\" in s:\n",
    "                return \"Associate\"\n",
    "            if \"bachelor\" in s or \"college\" in s:\n",
    "                return \"Bachelor\"\n",
    "            if any(k in s for k in [\"master\", \"graduate\", \"professional\"]):\n",
    "                return \"Master/Prof\"\n",
    "            if any(k in s for k in [\"doctor\", \"phd\", \"doctoral\"]):\n",
    "                return \"Doctoral\"\n",
    "            if any(k in s for k in [\"na\", \"unknown\", \"nan\", \"none\"]):\n",
    "                return \"Unknown\"\n",
    "            return s.title()\n",
    "        g[loe_col] = loe.map(map_loe)\n",
    "    # Forum counters -> binned\n",
    "    count_like = [c for c in g.columns if (\"number of \" in c.lower()) or (\"events within the forum\" in c.lower()) or (\"nforum\" in c.lower())]\n",
    "    for c in count_like:\n",
    "        g[c] = bin_counts(g[c])\n",
    "    return g\n",
    "\n",
    "def generalize_stage2(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    g = generalize_stage1(data)\n",
    "    lower = {c.lower(): c for c in g.columns}\n",
    "    # YoB -> 20-year\n",
    "    for key in [\"year of birth\", \"ear of birth\", \"yob\"]:\n",
    "        if key in lower:\n",
    "            g[lower[key]] = yob_to_20yr(g[lower[key]])\n",
    "            break\n",
    "    # postal -> first 2\n",
    "    if \"postalcode\" in lower:\n",
    "        g[lower[\"postalcode\"]] = postal2(g[lower[\"postalcode\"]])\n",
    "    # city -> first letter\n",
    "    if \"city\" in lower:\n",
    "        g[lower[\"city\"]] = g[lower[\"city\"]].astype(str).str[:1].replace({\"\": \"U\", \"nan\": \"U\"})\n",
    "    # Forum counters -> coarser\n",
    "    count_like = [c for c in g.columns if (\"number of \" in c.lower()) or (\"events within the forum\" in c.lower()) or (\"nforum\" in c.lower())]\n",
    "    for c in count_like:\n",
    "        g[c] = coarser_bin_counts(g[c])\n",
    "    return g\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e01ed238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Stage1_k': 1, 'Stage2_k': 1, 'files': ['/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/generalized_stage1.csv', '/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/generalized_stage2.csv']}\n",
      "{'TopStar_k': 199999, 'file': '/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/generalized_stage3_topstar.csv'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Stage 1\n",
    "g1 = generalize_stage1(df)\n",
    "g1_qis = [c for c in g1.columns if c not in identifiers]\n",
    "g1_k = k_anonymity_level(g1, g1_qis)\n",
    "g1.to_csv(OUT_GEN_STAGE1, index=False)\n",
    "\n",
    "# Stage 2\n",
    "g2 = generalize_stage2(df)\n",
    "g2_qis = [c for c in g2.columns if c not in identifiers]\n",
    "g2_k = k_anonymity_level(g2, g2_qis)\n",
    "g2.to_csv(OUT_GEN_STAGE2, index=False)\n",
    "\n",
    "print({\"Stage1_k\": g1_k, \"Stage2_k\": g2_k, \"files\": [OUT_GEN_STAGE1, OUT_GEN_STAGE2]})\n",
    "\n",
    "# Top-level '*' demo (not recommended for utility, but shows pure generalization can achieve k)\n",
    "g3 = df.copy()\n",
    "for c in g3.columns:\n",
    "    if c not in identifiers:\n",
    "        g3[c] = \"*\"\n",
    "g3_qis = [c for c in g3.columns if c not in identifiers]\n",
    "g3_k = k_anonymity_level(g3, g3_qis)\n",
    "g3.to_csv(OUT_GEN_TOPSTAR, index=False)\n",
    "print({\"TopStar_k\": g3_k, \"file\": OUT_GEN_TOPSTAR})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "786c4f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rows_source': 199999, 'deleted_rows': 68207, 'rows_kept': 131792, 'k_after': 5, 'file': '/Users/andrewrodriguez/Desktop/compsci1050/anonymity_and_ethics/de-identified_data/combination.csv'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Choose Stage 1 if it helps; otherwise Stage 2\n",
    "base_gen = g1 if g1_k >= 5 else g2\n",
    "base_qis = [c for c in base_gen.columns if c not in identifiers]\n",
    "combo_df, combo_deleted = record_suppression_k(base_gen, base_qis, k=5)\n",
    "combo_k = k_anonymity_level(combo_df, base_qis)\n",
    "combo_df.to_csv(OUT_COMBINATION, index=False)\n",
    "\n",
    "print({\n",
    "    \"rows_source\": len(df),\n",
    "    \"deleted_rows\": combo_deleted,\n",
    "    \"rows_kept\": len(combo_df),\n",
    "    \"k_after\": combo_k,\n",
    "    \"file\": OUT_COMBINATION\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
