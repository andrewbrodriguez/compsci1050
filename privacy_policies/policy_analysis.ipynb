{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290353c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: /Users/andrewrodriguez/Desktop/compsci1050\n",
      "DATA_DIR: /Users/andrewrodriguez/Desktop/compsci1050/privacy_policies/policy_texts\n",
      "FIG_DIR: /Users/andrewrodriguez/Desktop/compsci1050/figures\n",
      "REPORTS_DIR: /Users/andrewrodriguez/Desktop/compsci1050/reports\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r ../requirements.txt\n",
    "import os, json, math, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Project paths (adjust DATA_DIR to your folder if desired)\n",
    "BASE = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\"))\n",
    "DATA_DIR = \"/Users/andrewrodriguez/Desktop/compsci1050/privacy_policies/policy_texts\"\n",
    "FIG_DIR = \"/Users/andrewrodriguez/Desktop/compsci1050/privacy_policies/figures\"\n",
    "REPORTS_DIR = \"/Users/andrewrodriguez/Desktop/compsci1050/privacy_policies/reports\"\n",
    "\n",
    "from helpers import (\n",
    "    analyze_text, load_local_texts, fetch_policy_text, polite_sleep,\n",
    "    get_wayback_snapshots, fetch_wayback_content, html_to_text, domain_from_url\n",
    ")\n",
    "\n",
    "print('BASE:', BASE)\n",
    "print('DATA_DIR:', DATA_DIR)\n",
    "print('FIG_DIR:', FIG_DIR)\n",
    "print('REPORTS_DIR:', REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681a1cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 local files\n"
     ]
    }
   ],
   "source": [
    "texts = {}\n",
    "if os.path.isdir(DATA_DIR):\n",
    "    texts.update(load_local_texts(DATA_DIR))\n",
    "print(f'Loaded {len(texts)} local files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e763d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_chars</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_sents</th>\n",
       "      <th>flesch_reading_ease</th>\n",
       "      <th>flesch_kincaid_grade</th>\n",
       "      <th>gunning_fog</th>\n",
       "      <th>smog_index</th>\n",
       "      <th>dale_chall</th>\n",
       "      <th>coleman_liau</th>\n",
       "      <th>ari</th>\n",
       "      <th>avg_sentence_length</th>\n",
       "      <th>ttr</th>\n",
       "      <th>yule_k</th>\n",
       "      <th>entropy</th>\n",
       "      <th>avg_zipf</th>\n",
       "      <th>rare_frac</th>\n",
       "      <th>legalese_frac</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazon</th>\n",
       "      <td>27478</td>\n",
       "      <td>4164</td>\n",
       "      <td>160</td>\n",
       "      <td>25.075821</td>\n",
       "      <td>16.227089</td>\n",
       "      <td>19.747176</td>\n",
       "      <td>17.489301</td>\n",
       "      <td>11.730236</td>\n",
       "      <td>14.539193</td>\n",
       "      <td>17.644276</td>\n",
       "      <td>26.025000</td>\n",
       "      <td>0.219292</td>\n",
       "      <td>93.476508</td>\n",
       "      <td>8.219079</td>\n",
       "      <td>5.607517</td>\n",
       "      <td>0.009266</td>\n",
       "      <td>0.004277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apple</th>\n",
       "      <td>29703</td>\n",
       "      <td>4637</td>\n",
       "      <td>200</td>\n",
       "      <td>29.172227</td>\n",
       "      <td>14.950188</td>\n",
       "      <td>17.874388</td>\n",
       "      <td>16.162427</td>\n",
       "      <td>11.225745</td>\n",
       "      <td>13.362993</td>\n",
       "      <td>15.207038</td>\n",
       "      <td>23.185000</td>\n",
       "      <td>0.202908</td>\n",
       "      <td>99.283820</td>\n",
       "      <td>8.113057</td>\n",
       "      <td>5.679806</td>\n",
       "      <td>0.009692</td>\n",
       "      <td>0.009482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google</th>\n",
       "      <td>64446</td>\n",
       "      <td>10254</td>\n",
       "      <td>401</td>\n",
       "      <td>37.594990</td>\n",
       "      <td>14.368148</td>\n",
       "      <td>17.472431</td>\n",
       "      <td>15.655500</td>\n",
       "      <td>11.583315</td>\n",
       "      <td>12.816228</td>\n",
       "      <td>15.852249</td>\n",
       "      <td>25.571072</td>\n",
       "      <td>0.139813</td>\n",
       "      <td>97.857111</td>\n",
       "      <td>8.273859</td>\n",
       "      <td>5.675013</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>0.004821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta</th>\n",
       "      <td>35133</td>\n",
       "      <td>5546</td>\n",
       "      <td>149</td>\n",
       "      <td>23.316218</td>\n",
       "      <td>19.254035</td>\n",
       "      <td>21.596128</td>\n",
       "      <td>17.712588</td>\n",
       "      <td>11.769075</td>\n",
       "      <td>13.470429</td>\n",
       "      <td>21.978787</td>\n",
       "      <td>37.221477</td>\n",
       "      <td>0.129702</td>\n",
       "      <td>130.592344</td>\n",
       "      <td>7.616436</td>\n",
       "      <td>5.770186</td>\n",
       "      <td>0.007452</td>\n",
       "      <td>0.004968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>palantir</th>\n",
       "      <td>59335</td>\n",
       "      <td>8974</td>\n",
       "      <td>300</td>\n",
       "      <td>18.604502</td>\n",
       "      <td>18.095678</td>\n",
       "      <td>21.267763</td>\n",
       "      <td>18.613347</td>\n",
       "      <td>12.332505</td>\n",
       "      <td>14.800891</td>\n",
       "      <td>19.869173</td>\n",
       "      <td>29.913333</td>\n",
       "      <td>0.141534</td>\n",
       "      <td>102.235467</td>\n",
       "      <td>8.185523</td>\n",
       "      <td>5.646391</td>\n",
       "      <td>0.023589</td>\n",
       "      <td>0.011795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n_chars  n_words  n_sents  flesch_reading_ease  \\\n",
       "name                                                       \n",
       "amazon      27478     4164      160            25.075821   \n",
       "apple       29703     4637      200            29.172227   \n",
       "google      64446    10254      401            37.594990   \n",
       "meta        35133     5546      149            23.316218   \n",
       "palantir    59335     8974      300            18.604502   \n",
       "\n",
       "          flesch_kincaid_grade  gunning_fog  smog_index  dale_chall  \\\n",
       "name                                                                  \n",
       "amazon               16.227089    19.747176   17.489301   11.730236   \n",
       "apple                14.950188    17.874388   16.162427   11.225745   \n",
       "google               14.368148    17.472431   15.655500   11.583315   \n",
       "meta                 19.254035    21.596128   17.712588   11.769075   \n",
       "palantir             18.095678    21.267763   18.613347   12.332505   \n",
       "\n",
       "          coleman_liau        ari  avg_sentence_length       ttr      yule_k  \\\n",
       "name                                                                           \n",
       "amazon       14.539193  17.644276            26.025000  0.219292   93.476508   \n",
       "apple        13.362993  15.207038            23.185000  0.202908   99.283820   \n",
       "google       12.816228  15.852249            25.571072  0.139813   97.857111   \n",
       "meta         13.470429  21.978787            37.221477  0.129702  130.592344   \n",
       "palantir     14.800891  19.869173            29.913333  0.141534  102.235467   \n",
       "\n",
       "           entropy  avg_zipf  rare_frac  legalese_frac  \n",
       "name                                                    \n",
       "amazon    8.219079  5.607517   0.009266       0.004277  \n",
       "apple     8.113057  5.679806   0.009692       0.009482  \n",
       "google    8.273859  5.675013   0.012535       0.004821  \n",
       "meta      7.616436  5.770186   0.007452       0.004968  \n",
       "palantir  8.185523  5.646391   0.023589       0.011795  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '/Users/andrewrodriguez/Desktop/compsci1050/reports'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m df = pd.DataFrame(rows).set_index(\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m).sort_index()\n\u001b[32m      6\u001b[39m display(df.head())\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREPORTS_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmetrics.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mSaved metrics to reports/metrics.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/compsci1050/venv/lib/python3.12/site-packages/pandas/util/_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/compsci1050/venv/lib/python3.12/site-packages/pandas/core/generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/compsci1050/venv/lib/python3.12/site-packages/pandas/io/formats/format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/compsci1050/venv/lib/python3.12/site-packages/pandas/io/formats/csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/compsci1050/venv/lib/python3.12/site-packages/pandas/io/common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/compsci1050/venv/lib/python3.12/site-packages/pandas/io/common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '/Users/andrewrodriguez/Desktop/compsci1050/reports'"
     ]
    }
   ],
   "source": [
    "# Compute metrics into a DataFrame\n",
    "rows = []\n",
    "for name, text in texts.items():\n",
    "    rows.append(analyze_text(name, text))\n",
    "df = pd.DataFrame(rows).set_index('name').sort_index()\n",
    "display(df.head())\n",
    "df.to_csv(os.path.join(REPORTS_DIR, 'metrics.csv'), index=True)\n",
    "print('Saved metrics to reports/metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e95339c",
   "metadata": {},
   "source": [
    "## 3) Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842896aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1: Words vs Flesch-Kincaid Grade (length vs grade level)\n",
    "plt.figure()\n",
    "plt.scatter(df['n_words'], df['flesch_kincaid_grade'])\n",
    "for i, name in enumerate(df.index):\n",
    "    plt.annotate(name, (df['n_words'].iloc[i], df['flesch_kincaid_grade'].iloc[i]))\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Flesch–Kincaid Grade')\n",
    "plt.title('Figure 1: Length vs Grade Level')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'length_vs_grade.png'), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4836e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2: PCA (2D) on standardized features with k-means overlay\n",
    "features = ['n_words','n_sents','avg_sentence_length','flesch_kincaid_grade',\n",
    "            'gunning_fog','smog_index','dale_chall','coleman_liau','ari',\n",
    "            'ttr','yule_k','entropy','avg_zipf','rare_frac','legalese_frac']\n",
    "\n",
    "# Handle missing columns gracefully\n",
    "missing = [c for c in features if c not in df.columns]\n",
    "if missing:\n",
    "    print('Missing features (will be dropped):', missing)\n",
    "    features = [c for c in features if c in df.columns]\n",
    "\n",
    "X = df[features].replace([np.inf,-np.inf], np.nan).fillna(df[features].median())\n",
    "scaler = StandardScaler()\n",
    "Z = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2, random_state=0)\n",
    "P = pca.fit_transform(Z)\n",
    "\n",
    "best_k, best_sil = None, -1\n",
    "labels_by_k = {}\n",
    "for k in [2,3,4]:\n",
    "    km = KMeans(n_clusters=k, random_state=0, n_init='auto')\n",
    "    lbl = km.fit_predict(P)\n",
    "    sil = silhouette_score(P, lbl)\n",
    "    labels_by_k[k] = lbl\n",
    "    if sil > best_sil:\n",
    "        best_sil, best_k = sil, k\n",
    "\n",
    "labels = labels_by_k[best_k]\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(P[:,0], P[:,1])\n",
    "for i, name in enumerate(df.index):\n",
    "    plt.annotate(f\"{name} (c{labels[i]})\", (P[i,0], P[i,1]))\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.title(f'Figure 2: PCA + KMeans (k={best_k}, silhouette={best_sil:.3f})')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'pca_kmeans.png'), dpi=200)\n",
    "plt.show()\n",
    "\n",
    "df['cluster_k'] = best_k\n",
    "df['cluster_label'] = labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02989d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 3: Metric bars (standardized) per policy\n",
    "cols = ['flesch_kincaid_grade','gunning_fog','smog_index','dale_chall','coleman_liau','ari',\n",
    "        'avg_sentence_length','ttr','yule_k','entropy','avg_zipf','rare_frac','legalese_frac']\n",
    "cols = [c for c in cols if c in df.columns]\n",
    "\n",
    "M = df[cols].replace([np.inf,-np.inf], np.nan).fillna(df[cols].median())\n",
    "M = (M - M.mean())/M.std(ddof=0)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "M.plot(kind='bar', rot=45, legend=False)\n",
    "plt.xlabel('Policy')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Figure 3: Selected Metrics (standardized)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(FIG_DIR, 'metric_bars.png'), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c6860",
   "metadata": {},
   "source": [
    "## 4) Historical evolution for one site\n",
    "Pick a URL (ideally one of the above). We pull a few snapshots per year from the Internet Archive and recompute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeee062",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIST_URL = ''  # e.g., 'https://policies.google.com/privacy'\n",
    "if not HIST_URL:\n",
    "    # If not set, try to default to the first URL you fetched; otherwise skip\n",
    "    try:\n",
    "        from urllib.parse import urlparse\n",
    "        # reconstruct a plausible URL from the index name if needed\n",
    "        HIST_URL = 'https://policies.google.com/privacy'  # change me\n",
    "    except Exception:\n",
    "        HIST_URL = ''\n",
    "\n",
    "print('Historical target:', HIST_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ed742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch snapshots and compute metrics\n",
    "from src.helpers import analyze_text, get_wayback_snapshots, fetch_wayback_content, html_to_text, domain_from_url, polite_sleep\n",
    "hist_rows = []\n",
    "hist_df = pd.DataFrame()\n",
    "\n",
    "if HIST_URL:\n",
    "    try:\n",
    "        snaps = get_wayback_snapshots(HIST_URL, from_year=2015, to_year=datetime.now().year, limit_per_year=2)\n",
    "        print('Snapshots:', snaps[:6], '... (showing up to 6)')\n",
    "        for year, ts in snaps:\n",
    "            try:\n",
    "                html = fetch_wayback_content(HIST_URL, ts)\n",
    "                text = html_to_text(html)\n",
    "                rec = analyze_text(f\"{domain_from_url(HIST_URL)}_{ts}\", text)\n",
    "                rec['year'] = year\n",
    "                rec['timestamp'] = ts\n",
    "                hist_rows.append(rec)\n",
    "                polite_sleep(1.0)\n",
    "            except Exception as e:\n",
    "                print('Snapshot failed:', ts, e)\n",
    "        hist_df = pd.DataFrame(hist_rows).sort_values('timestamp')\n",
    "        if not hist_df.empty:\n",
    "            display(hist_df[['name','year','n_words','flesch_kincaid_grade']].head())\n",
    "            hist_df.to_csv(os.path.join(REPORTS_DIR, 'history_metrics.csv'), index=False)\n",
    "            print('Saved history to reports/history_metrics.csv')\n",
    "    except Exception as e:\n",
    "        print('Wayback query failed:', e)\n",
    "else:\n",
    "    print('HIST_URL not set; skipping history analysis.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 4: Words over time\n",
    "if 'hist_df' in globals() and not hist_df.empty:\n",
    "    plt.figure()\n",
    "    plt.plot(hist_df['year'], hist_df['n_words'], marker='o')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Words')\n",
    "    plt.title('Figure 4: Policy Length Over Time')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'history_words.png'), dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96aeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 5: Grade level over time\n",
    "if 'hist_df' in globals() and not hist_df.empty:\n",
    "    plt.figure()\n",
    "    plt.plot(hist_df['year'], hist_df['flesch_kincaid_grade'], marker='o')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Flesch–Kincaid Grade')\n",
    "    plt.title('Figure 5: Policy Grade Level Over Time')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(FIG_DIR, 'history_grade.png'), dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba128eda",
   "metadata": {},
   "source": [
    "## 5) Export a 2–4 page report\n",
    "We render a Markdown report with key figures and summary values. Convert to PDF/Docx as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7c1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Template\n",
    "\n",
    "def snapshots_md(df):\n",
    "    if df is None or df.empty:\n",
    "        return \"No snapshots found.\"\n",
    "    cols = ['year','timestamp','n_words','flesch_kincaid_grade']\n",
    "    df2 = df[cols].copy()\n",
    "    return df2.to_markdown(index=False)\n",
    "\n",
    "site_list = list(df.index) if 'df' in globals() and not df.empty else []\n",
    "historical_site = domain_from_url(HIST_URL) if HIST_URL else (site_list[0] if site_list else \"unknown\")\n",
    "\n",
    "summary_cols = ['n_words','n_sents','flesch_kincaid_grade','gunning_fog','smog_index','dale_chall']\n",
    "summary_cols = [c for c in summary_cols if c in (df.columns if 'df' in globals() else [])]\n",
    "summary_table_md = (df[summary_cols].to_markdown() if summary_cols else \"No metrics computed.\")\n",
    "\n",
    "best_k = int(df['cluster_k'].iloc[0]) if 'df' in globals() and 'cluster_k' in df.columns and not df.empty else 0\n",
    "\n",
    "template_path = os.path.join(REPORTS_DIR, 'report_template.md')\n",
    "with open(template_path, 'r') as f:\n",
    "    tpl = Template(f.read())\n",
    "\n",
    "report_text = tpl.render(\n",
    "    run_date=datetime.now().strftime('%Y-%m-%d'),\n",
    "    historical_site=historical_site,\n",
    "    key_findings_summary=\"(Fill after reviewing the figures)\",\n",
    "    site_list=site_list,\n",
    "    retrieval_method=\"from local text files and/or direct fetch of policy URLs on the same day\",\n",
    "    summary_table_md=summary_table_md,\n",
    "    best_k=best_k,\n",
    "    best_silhouette=float('nan'),\n",
    "    cluster_interpretation=\"(e.g., Cluster 0 = shorter/easier; Cluster 1 = longer/harder)\",\n",
    "    hist_len_trend=\"(e.g., generally increasing)\",\n",
    "    hist_grade_trend=\"(e.g., stable around grade 12)\",\n",
    "    hist_readability_trend=\"(e.g., modest decrease in readability after 2018)\",\n",
    "    interpretation=\"that policy readability varies substantially, and historical revisions often add length without proportional clarity gains\",\n",
    "    repo_link=\"https://github.com/yourname/privacy-policy-lab\",\n",
    "    snapshot_table_md=snapshots_md(hist_df if 'hist_df' in globals() else None)\n",
    ")\n",
    "\n",
    "out_path = os.path.join(REPORTS_DIR, 'lab_report.md')\n",
    "with open(out_path, 'w') as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print('Wrote report to', out_path)\n",
    "print('Convert to PDF with pandoc (optional):')\n",
    "print('  pandoc reports/lab_report.md -o reports/lab_report.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
